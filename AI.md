# AI

## Prompt Engineering

- https://www.cloudskillsboost.google/paths/20/course_templates/60/video/521863
- GenAI: Generative AI encompasses a broader range of models capable of generating various types of content beyond
- while LLM specifically refers to a subset of generative AI models focusing on language tasks.
- What is generative AI?
  - ![image](https://github.com/user-attachments/assets/2f50c8b0-569d-4df4-afe4-2fd78fbb62ea)
  - gen AI models are like conversational programs that can generate content based on the inputs supplied.
  - Gen AI models learn the patterns and structure from input training data and then create new data with similar characteristics.
  - exploring large language models, which are a highly sophisticated computer programs trained on gigantic amounts of data that can be text or images.
  - Large language models refer to large, general-purpose language models that can be pre-trained and then fine-tuned for specific purposes.
  - Parameters are the memories and knowledge that the machine has learned during model training.
  - When you submit a prompt to an LLM, it calculates the probability of the correct answer from its pre-trained model. The probability is determined through a task called pre-training. Pre-training an LLM involves feeding a massive dataset of text, images, and code to the model so that it can learn the underlying structure and patterns of the language.
  - ![image](https://github.com/user-attachments/assets/ae3dd3c5-e0aa-4598-ace3-188813b1da41)
  - Hallucinations are words or phrases that are generated by the model that are often nonsensical or grammatically incorrect.
  - This happens because LLMs can only understand the information they were trained on.
  - they often assume that the prompt is true. Hallucinations can be caused by a number of factors, including: The model is not trained on enough data.
  - ![image](https://github.com/user-attachments/assets/47db8b5a-a933-4578-b086-ffcf9d495ed5)

## Prompts:

- Prompts can be in the form of a question, and are categorized into four categories: zero-shot, one-shot, few-shot, and role prompts.
  - Zero-shot prompts do not contain any context or examples to assist the model.
  - One-shot prompts, however, provide one example to the model for context.
  - And few-shot prompts provide at least two examples to the model for context.
  - ![image](https://github.com/user-attachments/assets/f9dc69c1-ac94-4535-b952-4f73baa21384)
  - role prompts which require a frame of reference for the model to work from as it answers the questions.
  - ![image](https://github.com/user-attachments/assets/d20b3677-95f5-43aa-9cfd-594e55fee7a0)
  -  the two elements of a prompt: the preamble and the input
  -  preamble: introductory text you provide to give the model context and instructions before your main question or request.
  -  ![image](https://github.com/user-attachments/assets/46008da5-9acb-4bf7-b629-68d60a128fe9)
  -  input is the central request you're making to the LLM. Itâ€™s what the instruction or task will act upon,
  -  





   
